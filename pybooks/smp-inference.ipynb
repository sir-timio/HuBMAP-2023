{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1e2fb8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-08T13:47:45.972293Z",
     "iopub.status.busy": "2023-07-08T13:47:45.971825Z",
     "iopub.status.idle": "2023-07-08T13:48:05.642472Z",
     "shell.execute_reply": "2023-07-08T13:48:05.641428Z"
    },
    "papermill": {
     "duration": 19.680432,
     "end_time": "2023-07-08T13:48:05.645225",
     "exception": false,
     "start_time": "2023-07-08T13:47:45.964793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/dpn.py:255: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if block_type is 'proj':\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/dpn.py:258: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif block_type is 'down':\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/dpn.py:262: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  assert block_type is 'normal'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\n",
    "sys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\n",
    "sys.path.append('/kaggle/input/pytorch-image-models/pytorch-image-models')\n",
    "sys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models_pytorch')\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import AveragePrecision\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "import albumentations as A \n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import base64\n",
    "import typing as t\n",
    "import zlib\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "class CFG:\n",
    "    data_path = '/kaggle/input/hubmap-hacking-the-human-vasculature/'\n",
    "    batch_size = 1\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    th = 0.15\n",
    "    chepoint_dir = '/kaggle/input/models-hubmap-vasculative/'\n",
    "    model_types = ['UnetPlusPlus']\n",
    "    encoder_name_list = ['efficientnet-b7']\n",
    "    is_tta = True\n",
    "    size = 512\n",
    "    org_size = 512\n",
    "#     encoder_depth = 4\n",
    "#     decoder_channels = [512, 256, 128, 64]\n",
    "    \n",
    "    test_aug = [\n",
    "        A.Resize(size, size),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7416d6f9",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-07-08T13:48:05.656381Z",
     "iopub.status.busy": "2023-07-08T13:48:05.655407Z",
     "iopub.status.idle": "2023-07-08T13:49:00.951893Z",
     "shell.execute_reply": "2023-07-08T13:49:00.950449Z"
    },
    "papermill": {
     "duration": 55.305001,
     "end_time": "2023-07-08T13:49:00.954853",
     "exception": false,
     "start_time": "2023-07-08T13:48:05.649852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!mkdir /kaggle/working/packages\n",
    "!cp -r /kaggle/input/pycocotools/* /kaggle/working/packages\n",
    "os.chdir(\"/kaggle/working/packages/pycocotools-2.0.6/\")\n",
    "!python setup.py install\n",
    "!pip install . --no-index --find-links /kaggle/working/packages/\n",
    "os.chdir(\"/kaggle/working\")\n",
    "from pycocotools import _mask as coco_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05caa5ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T13:49:00.966125Z",
     "iopub.status.busy": "2023-07-08T13:49:00.965725Z",
     "iopub.status.idle": "2023-07-08T13:49:00.975492Z",
     "shell.execute_reply": "2023-07-08T13:49:00.974486Z"
    },
    "papermill": {
     "duration": 0.018251,
     "end_time": "2023-07-08T13:49:00.977864",
     "exception": false,
     "start_time": "2023-07-08T13:49:00.959613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HUBMAPDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.img_list = os.listdir(image_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        image_path = os.path.join(self.image_dir, self.img_list[idx])\n",
    "        image = cv2.imread(image_path)  \n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(image=image)\n",
    "            image = data['image']\n",
    "        return self.img_list[idx][:-4],image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be62fa3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T13:49:00.989256Z",
     "iopub.status.busy": "2023-07-08T13:49:00.988869Z",
     "iopub.status.idle": "2023-07-08T13:49:01.001337Z",
     "shell.execute_reply": "2023-07-08T13:49:01.000258Z"
    },
    "papermill": {
     "duration": 0.021054,
     "end_time": "2023-07-08T13:49:01.003644",
     "exception": false,
     "start_time": "2023-07-08T13:49:00.982590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EnsembleModel:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outputs = [model(x) for model in self.models]\n",
    "        outputs = torch.stack(outputs, dim=0)\n",
    "        avg_preds = torch.mean(outputs, dim=0)\n",
    "        return avg_preds\n",
    "\n",
    "    def add_model(self, model):\n",
    "        self.models.append(model)\n",
    "\n",
    "def build_ensemble_model():\n",
    "    model = EnsembleModel()\n",
    "    model_types = CFG.model_types\n",
    "    encoder_name_list = CFG.encoder_name_list\n",
    "    for _type, encoder_name in zip(model_types, encoder_name_list):\n",
    "        model_dir = CFG.chepoint_dir + _type + '/' + encoder_name + '/'\n",
    "        model_list = os.listdir(model_dir)\n",
    "        for i in range(len(model_list)):\n",
    "            if not model_list[i].endswith('.pth'):\n",
    "                continue\n",
    "            _model = smp.create_model(\n",
    "                    _type, encoder_name=encoder_name, in_channels=3, classes=1, encoder_weights=None,\n",
    "                )\n",
    "#             if _type == 'Unet':\n",
    "#                 _model = smp.Unet(encoder_name=encoder_name, activation='sigmoid', encoder_depth=CFG.encoder_depth, decoder_channels=CFG.decoder_channels, encoder_weights=None)\n",
    "#             elif _type == 'PSP':\n",
    "#                 _model = smp.PSPNet(encoder_name=encoder_name, activation='sigmoid', encoder_depth=CFG.encoder_depth, decoder_channels=CFG.decoder_channels, encoder_weights=None)\n",
    "#             elif _type == 'FPN':\n",
    "#                 _model = smp.FPN(encoder_name=encoder_name, activation='sigmoid', encoder_depth=CFG.encoder_depth, decoder_channels=CFG.decoder_channels, encoder_weights=None)\n",
    "#             elif _type == 'PAN':\n",
    "#                 _model = smp.PAN(encoder_name=encoder_name, activation='sigmoid', encoder_depth=CFG.encoder_depth, decoder_channels=CFG.decoder_channels, encoder_weights=None)\n",
    "#             elif _type == 'UnetPlusPlus':\n",
    "#                 _model = smp.UnetPlusPlus(encoder_name=encoder_name, activation='sigmoid', encoder_depth=CFG.encoder_depth, decoder_channels=CFG.decoder_channels, encoder_weights=None)\n",
    "            _model.to(CFG.device)\n",
    "            model_path = model_dir + model_list[i]\n",
    "            print(model_path)\n",
    "            _model.load_state_dict(torch.load(model_path, map_location=CFG.device))\n",
    "            _model.eval()\n",
    "            model.add_model(_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02cde172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T13:49:01.015074Z",
     "iopub.status.busy": "2023-07-08T13:49:01.014059Z",
     "iopub.status.idle": "2023-07-08T13:49:01.022373Z",
     "shell.execute_reply": "2023-07-08T13:49:01.021394Z"
    },
    "papermill": {
     "duration": 0.016283,
     "end_time": "2023-07-08T13:49:01.024711",
     "exception": false,
     "start_time": "2023-07-08T13:49:01.008428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TTA(x: torch.Tensor, model: nn.Module):\n",
    "    # x.shape=(batch,c,h,w)\n",
    "    shape = x.shape\n",
    "    x = [x, *[torch.rot90(x, k=i, dims=(-2, -1)) for i in range(1, 4)]]\n",
    "    x = torch.cat(x, dim=0)\n",
    "    x = model(x)\n",
    "    x = x.reshape(4, shape[0], 1, *shape[-2:])\n",
    "    x = [torch.rot90(x[i], k=-i, dims=(-2, -1)) for i in range(4)]\n",
    "    x = torch.stack(x, dim=0)\n",
    "    return x.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4e8c182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T13:49:01.035619Z",
     "iopub.status.busy": "2023-07-08T13:49:01.034840Z",
     "iopub.status.idle": "2023-07-08T13:49:01.057201Z",
     "shell.execute_reply": "2023-07-08T13:49:01.056102Z"
    },
    "papermill": {
     "duration": 0.030719,
     "end_time": "2023-07-08T13:49:01.059879",
     "exception": false,
     "start_time": "2023-07-08T13:49:01.029160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test:\n",
    "    def encode_binary_mask(self, mask: np.ndarray) -> t.Text:\n",
    "      \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n",
    "\n",
    "      # check input mask --\n",
    "      if mask.dtype != bool:\n",
    "        raise ValueError(\n",
    "            \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n",
    "            mask.dtype)\n",
    "\n",
    "      mask = np.squeeze(mask)\n",
    "      if len(mask.shape) != 2:\n",
    "        raise ValueError(\n",
    "            \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n",
    "            mask.shape)\n",
    "\n",
    "      # convert input mask to expected COCO API input --\n",
    "      mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "      mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "      mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "      # RLE encode mask --\n",
    "      encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "      # compress and base64 encoding --\n",
    "      binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "      base64_str = base64.b64encode(binary_str)\n",
    "      return base64_str\n",
    "    \n",
    "    \n",
    "    def encode_output(self,outputs,idx):\n",
    "        blood_vessel = torch.argmax(outputs, 1) \n",
    "        blood_vessel = blood_vessel == 1\n",
    "        blood_vessel = blood_vessel * 1\n",
    "    \n",
    "        blood_vessel = blood_vessel.cpu().numpy()\n",
    "        all_encode = {} \n",
    "        for i in range(blood_vessel.shape[0]):\n",
    "            list_encode = []\n",
    "            sliceImage = blood_vessel[i,:,:]\n",
    "            binarized = sliceImage > 0\n",
    "            coded_len = self.encode_binary_mask(binarized)\n",
    "            list_encode.append(coded_len)\n",
    "            all_encode[idx[i]] =list_encode\n",
    "        return all_encode\n",
    "\n",
    "    \n",
    "   \n",
    "    def get_test_transforms(self):\n",
    "        return A.Compose(CFG.test_aug)\n",
    "    \n",
    "    def test_dataloader(self,image_folder):\n",
    "        dataset = HUBMAPDataset(image_dir=image_folder, \n",
    "                                transform=self.get_test_transforms())\n",
    "        return DataLoader(dataset, batch_size=CFG.batch_size,shuffle=False, num_workers=4)\n",
    "    \n",
    "    \n",
    "\n",
    "    def evaluate(self,model):\n",
    "        ids = []\n",
    "        heights = []\n",
    "        widths = []\n",
    "        prediction_strings = []\n",
    "        sample = None\n",
    "        with torch.no_grad():\n",
    "            test_dataloader = self.test_dataloader(CFG.data_path + 'test/')\n",
    "            bar = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
    "            \n",
    "            for step, (idx, images) in bar:\n",
    "                images = images.to(CFG.device)\n",
    "                if CFG.is_tta:\n",
    "                    pred = TTA(images, model)\n",
    "                else:\n",
    "                    pred = model(images)\n",
    "                pred = F.interpolate(pred, size=[CFG.org_size, CFG.org_size], mode='bilinear', align_corners=False)\n",
    "                if sample is None: sample=pred\n",
    "                pred_string = ''\n",
    "                pred = (pred > CFG.th).float().cpu().numpy()\n",
    "                \n",
    "                for m in range(len(pred)):\n",
    "                    kernel = np.ones(shape=(3, 3), dtype=np.uint8)\n",
    "                    binary_mask = cv2.dilate((pred[m][0] * 255), kernel, 3)\n",
    "                    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_mask.astype(np.uint8))\n",
    "                    for i in range(1, num_labels):\n",
    "                        mask_i = np.zeros_like(binary_mask)\n",
    "                        mask_i[labels == i] = 1\n",
    "                        mask = mask_i[:, :, np.newaxis].astype(bool)\n",
    "                        score = 1.0\n",
    "                        encoded = self.encode_binary_mask(mask)\n",
    "                        if i==0:\n",
    "                            pred_string += f\"0 {score} {encoded.decode('utf-8')}\"\n",
    "\n",
    "                        else:\n",
    "                            pred_string += f\" 0 {score} {encoded.decode('utf-8')}\"\n",
    "                b, c, h, w = images.shape\n",
    "                ids.append(idx[0])\n",
    "                heights.append(h)\n",
    "                widths.append(w)\n",
    "                prediction_strings.append(pred_string)\n",
    "        return ids, heights, widths, prediction_strings, sample\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d500a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T13:49:01.070509Z",
     "iopub.status.busy": "2023-07-08T13:49:01.070166Z",
     "iopub.status.idle": "2023-07-08T13:49:01.074610Z",
     "shell.execute_reply": "2023-07-08T13:49:01.073601Z"
    },
    "papermill": {
     "duration": 0.012541,
     "end_time": "2023-07-08T13:49:01.076950",
     "exception": false,
     "start_time": "2023-07-08T13:49:01.064409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# top10 = [sample[i].detach().permute(1,2,0).cpu().numpy() for i in range(min(10,len(sample)))]\n",
    "# img = 0\n",
    "# for i in top10:\n",
    "#     img += i\n",
    "#     img = np.clip(img, 0, 1)\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98248b74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T13:49:01.088070Z",
     "iopub.status.busy": "2023-07-08T13:49:01.087046Z",
     "iopub.status.idle": "2023-07-08T13:49:11.157549Z",
     "shell.execute_reply": "2023-07-08T13:49:11.156412Z"
    },
    "papermill": {
     "duration": 10.078796,
     "end_time": "2023-07-08T13:49:11.160301",
     "exception": false,
     "start_time": "2023-07-08T13:49:01.081505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/models-hubmap-vasculative/UnetPlusPlus/efficientnet-b7/1.pth\n"
     ]
    }
   ],
   "source": [
    "model = build_ensemble_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b407852e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T13:49:11.171279Z",
     "iopub.status.busy": "2023-07-08T13:49:11.170933Z",
     "iopub.status.idle": "2023-07-08T13:49:17.071553Z",
     "shell.execute_reply": "2023-07-08T13:49:17.070347Z"
    },
    "papermill": {
     "duration": 5.909021,
     "end_time": "2023-07-08T13:49:17.074104",
     "exception": false,
     "start_time": "2023-07-08T13:49:11.165083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1002b67dcc8b427586c4ec63893a8d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = Test()\n",
    "ids, heights, widths, prediction_strings, sample=test.evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d98c7791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T13:49:17.086745Z",
     "iopub.status.busy": "2023-07-08T13:49:17.084937Z",
     "iopub.status.idle": "2023-07-08T13:49:18.198742Z",
     "shell.execute_reply": "2023-07-08T13:49:18.197385Z"
    },
    "papermill": {
     "duration": 1.122629,
     "end_time": "2023-07-08T13:49:18.201556",
     "exception": false,
     "start_time": "2023-07-08T13:49:17.078927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,height,width,prediction_string\r\n",
      "72e40acccadf,512,512, 0 1.0 eNpLTTSwSrM38jP0B0EDAyA2NADSYBachAIYB0z7G/mDsJFPWFy8OQBSkRBu 0 1.0 eNqLDco0s02yN/E28TX2NfI39INgAwNDIIaRBggmkPQHS/sZArGRrzEQm3ib+iTkphoAAMZxEl4= 0 1.0 eNrLT40yMsmxNzAw8Dc0AJP+BoZwHhwARRFiIBqmGpmHptzQwB/CAjEMIQZDeGDayA8kZuibn5lqAgDCiB2/ 0 1.0 eNpLCY8xN860t3Y38zb2NfIzNDDwh2N/AwMgBtKGIBrIMYCIAAk/Qz9jX2M/IzA28TX2MfUKjzQCANxVEpw= 0 1.0 eNqLjwgyNU2zN/c09TeEQAMDBIbxobSRH1QGBQAFDP0htIGhgT+YAxaAknAFSFoMDFENQBOC2gGhIFb7Q5wBoo38QA4x9DP0M/Yz8jX2M/YOi4g1BADZBCzn 0 1.0 eNoLycg2tEi3N/My8jf0M/Q3NDDwh5AGIApIGhhASRgHiQ3hQUUgAhBg6A/FfoYg7G/kZ+QXlBFlCgB+Xxjw 0 1.0 eNoLzs80MUuzt3W1cjf3NPQ3NDAAYRgw9IeRCBYygPGxqUNgEITRyKLIpJGfob+xb0RCsBEAXPQg7A== 0 1.0 eNoLyk80M86yN/c29jXyM/Yz9DcCYgQ0MABiQwMwjcozgDDALAjwN4RyDP2MgMaADDTyNfI38AdjPxBMTEg2AAAwxBtb\r\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = ids\n",
    "submission['height'] = heights\n",
    "submission['width'] = widths\n",
    "submission['prediction_string'] = prediction_strings\n",
    "submission = submission.set_index('id')\n",
    "submission.to_csv(\"submission.csv\")\n",
    "!cat submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3292a9bf",
   "metadata": {
    "papermill": {
     "duration": 0.004797,
     "end_time": "2023-07-08T13:49:18.211459",
     "exception": false,
     "start_time": "2023-07-08T13:49:18.206662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 108.068341,
   "end_time": "2023-07-08T13:49:21.547617",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-08T13:47:33.479276",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0122b1574f5247fa8dff407ea2ef5e20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "032ca7a760484649b1b0feb8371c2b7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f1396c3922774674bc9856949fd12a47",
       "placeholder": "​",
       "style": "IPY_MODEL_15039b8311984a039cfb8f9424826d05",
       "value": "100%"
      }
     },
     "1002b67dcc8b427586c4ec63893a8d63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_032ca7a760484649b1b0feb8371c2b7c",
        "IPY_MODEL_c0bba6a1363944f68ea91b933399c214",
        "IPY_MODEL_9c378a996ec042778a3d41501bbeefe7"
       ],
       "layout": "IPY_MODEL_2b1f50943c594b25b2c7eda8a81f52f6"
      }
     },
     "15039b8311984a039cfb8f9424826d05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1abbd6beed44442fbb8e671695c50e73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b1f50943c594b25b2c7eda8a81f52f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67eb3d872e3c45a9b82fdc8ad58f9463": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9c378a996ec042778a3d41501bbeefe7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0122b1574f5247fa8dff407ea2ef5e20",
       "placeholder": "​",
       "style": "IPY_MODEL_ae52c42a79e74f29a9c0bbfbd7c855fe",
       "value": " 1/1 [00:05&lt;00:00,  5.56s/it]"
      }
     },
     "ae52c42a79e74f29a9c0bbfbd7c855fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c0bba6a1363944f68ea91b933399c214": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1abbd6beed44442fbb8e671695c50e73",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_67eb3d872e3c45a9b82fdc8ad58f9463",
       "value": 1.0
      }
     },
     "f1396c3922774674bc9856949fd12a47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
